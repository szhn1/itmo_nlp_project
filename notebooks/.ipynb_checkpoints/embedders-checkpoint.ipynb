{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56d7fc2-a77b-40e0-bbc0-48b13d34e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/dataset_tg.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3216d91-a4c7-45f2-952e-c2a4bcf5bc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_channel\n",
       "3     15747\n",
       "1      8552\n",
       "6      6105\n",
       "4      5073\n",
       "2      3916\n",
       "18     2891\n",
       "5      2476\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"id_channel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6ed6dd-9b95-4828-8cd1-da509ffadc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message_id</th>\n",
       "      <th>views_o0</th>\n",
       "      <th>views_o1</th>\n",
       "      <th>views_o2</th>\n",
       "      <th>views_o3</th>\n",
       "      <th>forwards_o0</th>\n",
       "      <th>forwards_o1</th>\n",
       "      <th>forwards_o2</th>\n",
       "      <th>...</th>\n",
       "      <th>best_ctr_reactions_0_3</th>\n",
       "      <th>viral_ml</th>\n",
       "      <th>viral_final</th>\n",
       "      <th>llm_json</th>\n",
       "      <th>is_economic</th>\n",
       "      <th>topic</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reason</th>\n",
       "      <th>economic_signals</th>\n",
       "      <th>noise_signals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00027151-a524-4d93-a820-116398fb81bb</td>\n",
       "      <td>492127.0</td>\n",
       "      <td>603269.0</td>\n",
       "      <td>619397.0</td>\n",
       "      <td>625475.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.173209</td>\n",
       "      <td>0.406649</td>\n",
       "      <td>{'confidence': 0.96, 'economic_signals': array...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Текст содержит лишь политические и военные выс...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0003b835-cf4a-43ff-b155-a144cf56b7f8</td>\n",
       "      <td>486195.0</td>\n",
       "      <td>507393.0</td>\n",
       "      <td>514469.0</td>\n",
       "      <td>517508.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.150123</td>\n",
       "      <td>0.445509</td>\n",
       "      <td>{'confidence': 0.9, 'economic_signals': array(...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Новость посвящена уголовному делу о хищении ср...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0005535a-74a9-4cb9-853f-ce04612d2f94</td>\n",
       "      <td>455967.0</td>\n",
       "      <td>609468.0</td>\n",
       "      <td>627631.0</td>\n",
       "      <td>634731.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.170353</td>\n",
       "      <td>0.396754</td>\n",
       "      <td>{'confidence': 0.95, 'economic_signals': array...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Новость описывает процесс поступления детей в ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0007e2f8-787d-404f-91ff-e2582096a4a7</td>\n",
       "      <td>22376.0</td>\n",
       "      <td>23594.0</td>\n",
       "      <td>23735.0</td>\n",
       "      <td>23825.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.703622</td>\n",
       "      <td>{'confidence': 0.96, 'economic_signals': array...</td>\n",
       "      <td>True</td>\n",
       "      <td>Санкции и геополитика</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Новость посвящена позиции Сербии по санкциям Е...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>000884a5-8291-4ec1-805f-ac131112aaf7</td>\n",
       "      <td>19493.0</td>\n",
       "      <td>20605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.680369</td>\n",
       "      <td>{'confidence': 0.96, 'economic_signals': array...</td>\n",
       "      <td>True</td>\n",
       "      <td>Рынки капитала</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Новость описывает падение фондового рынка и ра...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                            message_id  views_o0  \\\n",
       "0             0           0  00027151-a524-4d93-a820-116398fb81bb  492127.0   \n",
       "1             1           2  0003b835-cf4a-43ff-b155-a144cf56b7f8  486195.0   \n",
       "2             2           4  0005535a-74a9-4cb9-853f-ce04612d2f94  455967.0   \n",
       "3             3           7  0007e2f8-787d-404f-91ff-e2582096a4a7   22376.0   \n",
       "4             4           8  000884a5-8291-4ec1-805f-ac131112aaf7   19493.0   \n",
       "\n",
       "   views_o1  views_o2  views_o3  forwards_o0  forwards_o1  forwards_o2  ...  \\\n",
       "0  603269.0  619397.0  625475.0        381.0        415.0        449.0  ...   \n",
       "1  507393.0  514469.0  517508.0        273.0        273.0        273.0  ...   \n",
       "2  609468.0  627631.0  634731.0        448.0        551.0        551.0  ...   \n",
       "3   23594.0   23735.0   23825.0          5.0          9.0          9.0  ...   \n",
       "4   20605.0       NaN       NaN         64.0         67.0          NaN  ...   \n",
       "\n",
       "   best_ctr_reactions_0_3  viral_ml  viral_final  \\\n",
       "0                     NaN -0.173209     0.406649   \n",
       "1                     NaN -0.150123     0.445509   \n",
       "2                     NaN -0.170353     0.396754   \n",
       "3                     NaN  0.005396     0.703622   \n",
       "4                 0.00041  0.024601     0.680369   \n",
       "\n",
       "                                            llm_json  is_economic  \\\n",
       "0  {'confidence': 0.96, 'economic_signals': array...        False   \n",
       "1  {'confidence': 0.9, 'economic_signals': array(...        False   \n",
       "2  {'confidence': 0.95, 'economic_signals': array...        False   \n",
       "3  {'confidence': 0.96, 'economic_signals': array...         True   \n",
       "4  {'confidence': 0.96, 'economic_signals': array...         True   \n",
       "\n",
       "                   topic  confidence  \\\n",
       "0                   None        0.96   \n",
       "1                   None        0.90   \n",
       "2                   None        0.95   \n",
       "3  Санкции и геополитика        0.96   \n",
       "4         Рынки капитала        0.96   \n",
       "\n",
       "                                              reason  economic_signals  \\\n",
       "0  Текст содержит лишь политические и военные выс...               NaN   \n",
       "1  Новость посвящена уголовному делу о хищении ср...               NaN   \n",
       "2  Новость описывает процесс поступления детей в ...               NaN   \n",
       "3  Новость посвящена позиции Сербии по санкциям Е...               NaN   \n",
       "4  Новость описывает падение фондового рынка и ра...               NaN   \n",
       "\n",
       "  noise_signals  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36601883-95ed-4043-8d6f-8898248d1369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44760, 95)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67784bf2-aab7-463f-9cb0-397ad3b33db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "736e5b91-0ddf-4999-9651-b0cab84e9599",
   "metadata": {},
   "source": [
    "в консоли для сбора мелкого датасета из dataset_tg_cleaned: \n",
    "python prepare_df_filtered.py --only_economic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1b05a-9df5-4fa0-8d9a-e41c11062f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f6692c-4420-422d-957d-3f1a30022a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARS: {'count': 18618, 'mean': 451.36663443978944, 'p50': 334.0, 'p75': 558.0, 'p90': 908.0, 'p95': 1127.1499999999978, 'p99': 2348.129999999979, 'max': 4067.0}\n",
      "WORDS: {'count': 18618, 'mean': 63.3464926415297, 'p50': 47.0, 'p75': 77.0, 'p90': 124.29999999999927, 'p95': 158.0, 'p99': 317.8299999999981, 'max': 634.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/cleaned_news_exp.csv\")\n",
    "texts = df[\"message\"].fillna(\"\").astype(str)\n",
    "\n",
    "df_len = pd.DataFrame({\n",
    "    \"chars\": texts.str.len(),\n",
    "    \"words\": texts.str.split().map(len),\n",
    "})\n",
    "\n",
    "def qstats(s):\n",
    "    return {\n",
    "        \"count\": int(s.count()),\n",
    "        \"mean\": float(s.mean()),\n",
    "        \"p50\": float(s.quantile(0.50)),\n",
    "        \"p75\": float(s.quantile(0.75)),\n",
    "        \"p90\": float(s.quantile(0.90)),\n",
    "        \"p95\": float(s.quantile(0.95)),\n",
    "        \"p99\": float(s.quantile(0.99)),\n",
    "        \"max\": float(s.max()),\n",
    "    }\n",
    "\n",
    "print(\"CHARS:\", qstats(df_len[\"chars\"]))\n",
    "print(\"WORDS:\", qstats(df_len[\"words\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84865903-f89d-4456-bff2-2fe2bac564f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da75a5aa8f814fbd8846e73ba86e882c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe71e39b13ee47f088beb816bc1af27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350530d49d9a439a874406539f70dbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de98d505f2a4edebad76b1cb19b6fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing:   0%|          | 0/73 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "Tokenizing: 100%|██████████| 73/73 [00:01<00:00, 48.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E5 token lens: {'count': 18618, 'mean': 115.6950263186164, 'p50': 87.0, 'p75': 140.0, 'p90': 221.29999999999927, 'p95': 286.0, 'p99': 587.0, 'max': 1226.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tok_e5 = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-base\")\n",
    "\n",
    "def token_lens(tokenizer, texts, batch_size=256):\n",
    "    lens = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=False, truncation=False, add_special_tokens=True)\n",
    "        lens.extend([len(ids) for ids in enc[\"input_ids\"]])\n",
    "    return np.array(lens)\n",
    "\n",
    "e5_lens = token_lens(tok_e5, texts.tolist(), batch_size=256)\n",
    "\n",
    "def qstats_np(a):\n",
    "    return {\n",
    "        \"count\": int(a.size),\n",
    "        \"mean\": float(a.mean()),\n",
    "        \"p50\": float(np.quantile(a, 0.50)),\n",
    "        \"p75\": float(np.quantile(a, 0.75)),\n",
    "        \"p90\": float(np.quantile(a, 0.90)),\n",
    "        \"p95\": float(np.quantile(a, 0.95)),\n",
    "        \"p99\": float(np.quantile(a, 0.99)),\n",
    "        \"max\": float(a.max()),\n",
    "    }\n",
    "\n",
    "print(\"E5 token lens:\", qstats_np(e5_lens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031fb6c6-aa75-4fd8-a658-6e6a8d028bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5219af17b804760b1df5821a2f741ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01345bb1cb8345f786bc39b7234f00a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845bbcfb96ab47648d0a5ddc3bd11da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 73/73 [00:01<00:00, 46.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTE token lens: {'count': 18618, 'mean': 115.6950263186164, 'p50': 87.0, 'p75': 140.0, 'p90': 221.29999999999927, 'p95': 286.0, 'p99': 587.0, 'max': 1226.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tok_gte = AutoTokenizer.from_pretrained(\"Alibaba-NLP/gte-multilingual-base\", trust_remote_code=True)\n",
    "gte_lens = token_lens(tok_gte, texts.tolist(), batch_size=256)\n",
    "print(\"GTE token lens:\", qstats_np(gte_lens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c321a-38ce-49b2-a230-5e6596d67099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e77d2764-d954-4337-adea-1fded64c8346",
   "metadata": {},
   "source": [
    "### intfloat/multilingual-e5-small \n",
    "python embed_st.py   --input ../data/cleaned_news_exp.csv   --model intfloat/multilingual-e5-small   --prefix \"passage: \"   --out embeddings/emb_e5_small_fp16.npy --batch_size 16   --max_len 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfc824-2e4d-4770-b69c-888aec4eab0d",
   "metadata": {},
   "source": [
    "### intfloat/multilingual-e5-base\n",
    "python embed_st.py   --input ../data/cleaned_news_exp.csv   --model intfloat/multilingual-e5-base   --prefix \"passage: \"   --out embeddings/emb_e5_base_fp16.npy --batch_size 16   --max_len 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc4487-cd1c-4626-877f-8f8aeeebcea7",
   "metadata": {},
   "source": [
    "### intfloat/multilingual-e5-large\n",
    "python embed_st.py   --input ../data/cleaned_news_exp.csv   --model intfloat/multilingual-e5-large   --prefix \"passage: \"   --out embeddings/emb_e5_large_fp16.npy  --batch_size 16   --max_len 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd379f0-d0be-46dd-a092-aa927ee2174c",
   "metadata": {},
   "source": [
    "### sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \n",
    "python embed_st.py   --input ../data/cleaned_news_exp.csv   --model sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2   --out embeddings/emb_minilm_fp16.npy  --batch_size 32   --max_len 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384438a-b102-4bbd-ae0e-a418f7e5072e",
   "metadata": {},
   "source": [
    "### Alibaba-NLP/gte-multilingual-base\n",
    "python embed_gte.py   --input ../data/cleaned_news_exp.csv   --out embeddings/emb_gte_fp16.npy   --rowmap embeddings/rowmap_gte.csv   --batch_size 4 --max_len 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a4c3f3-c466-4d1c-9018-253ec57dc0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"message_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fc8ff4-180c-4dab-a351-d63b735231bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>id_channel</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007e2f8-787d-404f-91ff-e2582096a4a7</td>\n",
       "      <td>18</td>\n",
       "      <td>Сербия согласна поддержать санкции Евросоюза п...</td>\n",
       "      <td>2025-07-26 07:01:09</td>\n",
       "      <td>Санкции и геополитика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000884a5-8291-4ec1-805f-ac131112aaf7</td>\n",
       "      <td>6</td>\n",
       "      <td>Китайский рынок акций упал сильнее всего с апр...</td>\n",
       "      <td>2025-09-04 10:16:56</td>\n",
       "      <td>Рынки капитала</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000b0331-92a9-4eb4-9f58-d00811257758</td>\n",
       "      <td>18</td>\n",
       "      <td>Министерство труда США отменило рекомендации 2...</td>\n",
       "      <td>2025-05-29 04:05:09</td>\n",
       "      <td>Государственная экономическая политика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000b8df7-d902-41eb-b668-900614902f0a</td>\n",
       "      <td>6</td>\n",
       "      <td>Чистая прибыль Московской биржи по МСФО во вто...</td>\n",
       "      <td>2025-08-26 11:40:55</td>\n",
       "      <td>Корпоративные финансы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0011adea-7a98-4dcc-b753-905597b42788</td>\n",
       "      <td>4</td>\n",
       "      <td>США хотят получить нефть и «всё, что угодно» о...</td>\n",
       "      <td>2025-02-22 20:57:18</td>\n",
       "      <td>Сырьевые рынки</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             message_id  id_channel  \\\n",
       "0  0007e2f8-787d-404f-91ff-e2582096a4a7          18   \n",
       "1  000884a5-8291-4ec1-805f-ac131112aaf7           6   \n",
       "2  000b0331-92a9-4eb4-9f58-d00811257758          18   \n",
       "3  000b8df7-d902-41eb-b668-900614902f0a           6   \n",
       "4  0011adea-7a98-4dcc-b753-905597b42788           4   \n",
       "\n",
       "                                             message                 date  \\\n",
       "0  Сербия согласна поддержать санкции Евросоюза п...  2025-07-26 07:01:09   \n",
       "1  Китайский рынок акций упал сильнее всего с апр...  2025-09-04 10:16:56   \n",
       "2  Министерство труда США отменило рекомендации 2...  2025-05-29 04:05:09   \n",
       "3  Чистая прибыль Московской биржи по МСФО во вто...  2025-08-26 11:40:55   \n",
       "4  США хотят получить нефть и «всё, что угодно» о...  2025-02-22 20:57:18   \n",
       "\n",
       "                                    topic  \n",
       "0                   Санкции и геополитика  \n",
       "1                          Рынки капитала  \n",
       "2  Государственная экономическая политика  \n",
       "3                   Корпоративные финансы  \n",
       "4                          Сырьевые рынки  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"message_id\", \"id_channel\", \"message\", \"date\", \"topic\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c8fd46-90b0-4578-be86-2aa0fec3affe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0007e2f8-787d-404f-91ff-e2582096a4a7</td>\n",
       "      <td>2025-07-26 07:01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000884a5-8291-4ec1-805f-ac131112aaf7</td>\n",
       "      <td>2025-09-04 10:16:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000b0331-92a9-4eb4-9f58-d00811257758</td>\n",
       "      <td>2025-05-29 04:05:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>000b8df7-d902-41eb-b668-900614902f0a</td>\n",
       "      <td>2025-08-26 11:40:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0011adea-7a98-4dcc-b753-905597b42788</td>\n",
       "      <td>2025-02-22 20:57:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                            message_id                 date\n",
       "0       0  0007e2f8-787d-404f-91ff-e2582096a4a7  2025-07-26 07:01:09\n",
       "1       1  000884a5-8291-4ec1-805f-ac131112aaf7  2025-09-04 10:16:56\n",
       "2       2  000b0331-92a9-4eb4-9f58-d00811257758  2025-05-29 04:05:09\n",
       "3       3  000b8df7-d902-41eb-b668-900614902f0a  2025-08-26 11:40:55\n",
       "4       4  0011adea-7a98-4dcc-b753-905597b42788  2025-02-22 20:57:18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowmap = pd.read_csv(\"embeddings/rowmap.csv\")\n",
    "rowmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f82434-6e55-43c3-a812-b9ac488728a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_e5_base_fp16.npy (18618, 768) OK\n",
      "emb_e5_large_fp16.npy (18618, 1024) OK\n",
      "emb_e5_small_fp16.npy (18618, 384) OK\n",
      "emb_gte_fp16.npy (18618, 768) OK\n",
      "emb_minilm_fp16.npy (18618, 384) OK\n"
     ]
    }
   ],
   "source": [
    "# проверка согласованности\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "rowmap = pd.read_csv(\"embeddings/rowmap.csv\")\n",
    "N = len(rowmap)\n",
    "\n",
    "emb_dir = Path(\"embeddings\")\n",
    "for p in sorted(emb_dir.glob(\"emb_*_fp16.npy\")):\n",
    "    E = np.load(p, mmap_mode=\"r\")\n",
    "    print(p.name, E.shape, \"OK\" if E.shape[0] == N else \"MISMATCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123feb7-9812-4959-8720-3ee75f561737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dd3ab8f-b9cf-4c0b-bce4-a349eba8ec1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b908a9b0a146edb0c4dbd47b0a822a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, re, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "JUDGE_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "judge_tokenizer = AutoTokenizer.from_pretrained(JUDGE_MODEL, trust_remote_code=True)\n",
    "judge_model = AutoModelForCausalLM.from_pretrained(\n",
    "    JUDGE_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "judge_model.eval()\n",
    "\n",
    "def _extract_first_json_obj(text: str):\n",
    "    text = (text or \"\").strip()\n",
    "    if text.startswith(\"{\") and text.endswith(\"}\"):\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except Exception:\n",
    "            pass\n",
    "    for m in re.finditer(r\"\\{.*?\\}\", text, flags=re.DOTALL):\n",
    "        cand = m.group(0)\n",
    "        try:\n",
    "            return json.loads(cand)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "@torch.inference_mode()\n",
    "def judge_pair(query: str, snippet: str, max_new_tokens: int = 40) -> int:\n",
    "    user = f\"Запрос:\\n{query}\\n\\nДокумент:\\n{snippet}\\n\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": JUDGE_SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "    prompt = judge_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = judge_tokenizer(prompt, return_tensors=\"pt\").to(judge_model.device)\n",
    "\n",
    "    out = judge_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        eos_token_id=judge_tokenizer.eos_token_id,\n",
    "        pad_token_id=judge_tokenizer.eos_token_id,\n",
    "    )\n",
    "    gen = judge_tokenizer.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    data = _extract_first_json_obj(gen)\n",
    "\n",
    "    if isinstance(data, dict) and data.get(\"relevance\") in (0, 1, 2):\n",
    "        return int(data[\"relevance\"])\n",
    "\n",
    "    return 0\n",
    "\n",
    "def judge_with_llm(query: str, docs: list[str]) -> list[int]:\n",
    "    return [judge_pair(query, d) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf6ecd15-e7f5-42aa-b422-56de5b99422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_SYSTEM = \"\"\"Ты - строгий эксперт по информационному поиску по новостям об экономике.\n",
    "\n",
    "Оцени, насколько найденный документ релевантен запросу.\n",
    "\n",
    "Запрос:\n",
    "{query}\n",
    "\n",
    "Документ:\n",
    "{snippet}\n",
    "\n",
    "Оценка:\n",
    "2 — документ напрямую отвечает на запрос или описывает то же событие.\n",
    "1 — документ тематически близок, но не отвечает напрямую запросу.\n",
    "0 — документ нерелевантен.\n",
    "\n",
    "Верни ТОЛЬКО JSON и ничего более:\n",
    "{\"relevance\": 0|1|2}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b156aa28-84e6-4281-9b31-d78ab5323091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings: ['emb_e5_base_fp16.npy', 'emb_e5_large_fp16.npy', 'emb_e5_small_fp16.npy', 'emb_gte_fp16.npy', 'emb_minilm_fp16.npy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedders:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Queries for emb_e5_base_fp16.npy:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[AThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "\n",
      "Queries for emb_e5_base_fp16.npy:   5%|▌         | 1/20 [00:07<02:29,  7.86s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  10%|█         | 2/20 [00:09<01:20,  4.48s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  15%|█▌        | 3/20 [00:12<00:57,  3.37s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  20%|██        | 4/20 [00:14<00:45,  2.85s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  25%|██▌       | 5/20 [00:16<00:39,  2.61s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  30%|███       | 6/20 [00:18<00:33,  2.42s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  35%|███▌      | 7/20 [00:20<00:29,  2.30s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  40%|████      | 8/20 [00:22<00:26,  2.21s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  45%|████▌     | 9/20 [00:24<00:23,  2.14s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  50%|█████     | 10/20 [00:26<00:20,  2.09s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  55%|█████▌    | 11/20 [00:28<00:19,  2.12s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  60%|██████    | 12/20 [00:30<00:16,  2.08s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  65%|██████▌   | 13/20 [00:32<00:14,  2.06s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  70%|███████   | 14/20 [00:34<00:12,  2.06s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  75%|███████▌  | 15/20 [00:36<00:10,  2.04s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  80%|████████  | 16/20 [00:38<00:08,  2.04s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  85%|████████▌ | 17/20 [00:40<00:06,  2.03s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  90%|█████████ | 18/20 [00:42<00:04,  2.06s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy:  95%|█████████▌| 19/20 [00:44<00:02,  2.04s/it]\u001b[A\n",
      "Queries for emb_e5_base_fp16.npy: 100%|██████████| 20/20 [00:46<00:00,  2.03s/it]\u001b[A\n",
      "Embedders:  20%|██        | 1/5 [00:46<03:07, 46.83s/it]                         \u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:   5%|▌         | 1/20 [00:06<02:12,  6.98s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  10%|█         | 2/20 [00:08<01:13,  4.06s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  15%|█▌        | 3/20 [00:11<00:53,  3.13s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  20%|██        | 4/20 [00:13<00:43,  2.69s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  25%|██▌       | 5/20 [00:15<00:36,  2.45s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  30%|███       | 6/20 [00:17<00:32,  2.30s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  35%|███▌      | 7/20 [00:19<00:28,  2.22s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  40%|████      | 8/20 [00:21<00:26,  2.17s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  45%|████▌     | 9/20 [00:23<00:23,  2.13s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  50%|█████     | 10/20 [00:25<00:20,  2.09s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  55%|█████▌    | 11/20 [00:27<00:18,  2.07s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  60%|██████    | 12/20 [00:29<00:16,  2.07s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  65%|██████▌   | 13/20 [00:31<00:14,  2.06s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  70%|███████   | 14/20 [00:33<00:12,  2.07s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  75%|███████▌  | 15/20 [00:35<00:10,  2.05s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  80%|████████  | 16/20 [00:37<00:08,  2.04s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  85%|████████▌ | 17/20 [00:39<00:06,  2.04s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  90%|█████████ | 18/20 [00:41<00:04,  2.06s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy:  95%|█████████▌| 19/20 [00:43<00:02,  2.06s/it]\u001b[A\n",
      "Queries for emb_e5_large_fp16.npy: 100%|██████████| 20/20 [00:45<00:00,  2.06s/it]\u001b[A\n",
      "Embedders:  40%|████      | 2/5 [01:32<02:18, 46.24s/it]                          \u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:   5%|▌         | 1/20 [00:07<02:18,  7.30s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  10%|█         | 2/20 [00:09<01:16,  4.25s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  15%|█▌        | 3/20 [00:11<00:55,  3.27s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  20%|██        | 4/20 [00:13<00:45,  2.83s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  25%|██▌       | 5/20 [00:15<00:38,  2.60s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  30%|███       | 6/20 [00:17<00:33,  2.42s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  35%|███▌      | 7/20 [00:20<00:30,  2.31s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  40%|████      | 8/20 [00:22<00:26,  2.23s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  45%|████▌     | 9/20 [00:24<00:23,  2.16s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  50%|█████     | 10/20 [00:26<00:21,  2.12s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  55%|█████▌    | 11/20 [00:28<00:18,  2.10s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  60%|██████    | 12/20 [00:30<00:16,  2.08s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  65%|██████▌   | 13/20 [00:32<00:14,  2.08s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  70%|███████   | 14/20 [00:34<00:12,  2.09s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  75%|███████▌  | 15/20 [00:36<00:10,  2.07s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  80%|████████  | 16/20 [00:38<00:08,  2.07s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  85%|████████▌ | 17/20 [00:40<00:06,  2.05s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  90%|█████████ | 18/20 [00:42<00:04,  2.08s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy:  95%|█████████▌| 19/20 [00:44<00:02,  2.08s/it]\u001b[A\n",
      "Queries for emb_e5_small_fp16.npy: 100%|██████████| 20/20 [00:46<00:00,  2.08s/it]\u001b[A\n",
      "Embedders:  60%|██████    | 3/5 [02:19<01:33, 46.51s/it]                          \u001b[A\n",
      "Queries for emb_gte_fp16.npy:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[ASome weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\n",
      "Queries for emb_gte_fp16.npy:   5%|▌         | 1/20 [00:04<01:20,  4.21s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  10%|█         | 2/20 [00:06<00:52,  2.92s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  15%|█▌        | 3/20 [00:08<00:42,  2.52s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  20%|██        | 4/20 [00:10<00:37,  2.32s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  25%|██▌       | 5/20 [00:12<00:33,  2.21s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  30%|███       | 6/20 [00:14<00:30,  2.15s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  35%|███▌      | 7/20 [00:16<00:27,  2.11s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  40%|████      | 8/20 [00:18<00:25,  2.09s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  45%|████▌     | 9/20 [00:20<00:22,  2.07s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  50%|█████     | 10/20 [00:22<00:20,  2.06s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  55%|█████▌    | 11/20 [00:24<00:18,  2.04s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  60%|██████    | 12/20 [00:26<00:16,  2.04s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  65%|██████▌   | 13/20 [00:28<00:14,  2.03s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  70%|███████   | 14/20 [00:30<00:12,  2.03s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  75%|███████▌  | 15/20 [00:32<00:10,  2.02s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  80%|████████  | 16/20 [00:34<00:08,  2.02s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  85%|████████▌ | 17/20 [00:36<00:06,  2.02s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  90%|█████████ | 18/20 [00:38<00:04,  2.02s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy:  95%|█████████▌| 19/20 [00:40<00:02,  2.03s/it]\u001b[A\n",
      "Queries for emb_gte_fp16.npy: 100%|██████████| 20/20 [00:42<00:00,  2.04s/it]\u001b[A\n",
      "Embedders:  80%|████████  | 4/5 [03:02<00:45, 45.05s/it]                     \u001b[A\n",
      "Queries for emb_minilm_fp16.npy:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:   5%|▌         | 1/20 [00:06<02:02,  6.45s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  10%|█         | 2/20 [00:08<01:10,  3.89s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  15%|█▌        | 3/20 [00:10<00:52,  3.08s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  20%|██        | 4/20 [00:12<00:43,  2.69s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  25%|██▌       | 5/20 [00:14<00:37,  2.47s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  30%|███       | 6/20 [00:16<00:32,  2.32s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  35%|███▌      | 7/20 [00:18<00:29,  2.25s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  40%|████      | 8/20 [00:21<00:26,  2.21s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  45%|████▌     | 9/20 [00:23<00:23,  2.17s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  50%|█████     | 10/20 [00:25<00:21,  2.14s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  55%|█████▌    | 11/20 [00:27<00:19,  2.14s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  60%|██████    | 12/20 [00:29<00:16,  2.11s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  65%|██████▌   | 13/20 [00:31<00:14,  2.10s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  70%|███████   | 14/20 [00:33<00:12,  2.09s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  75%|███████▌  | 15/20 [00:35<00:10,  2.09s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  80%|████████  | 16/20 [00:37<00:08,  2.09s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  85%|████████▌ | 17/20 [00:39<00:06,  2.09s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  90%|█████████ | 18/20 [00:41<00:04,  2.10s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy:  95%|█████████▌| 19/20 [00:44<00:02,  2.09s/it]\u001b[A\n",
      "Queries for emb_minilm_fp16.npy: 100%|██████████| 20/20 [00:46<00:00,  2.10s/it]\u001b[A\n",
      "Embedders: 100%|██████████| 5/5 [03:48<00:00, 45.70s/it]                        \u001b[A\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "DATA_PATH = Path(\"cleaned_news_exp.csv\")    \n",
    "ROWMAP_PATH = Path(\"embeddings/rowmap.csv\")\n",
    "EMB_DIR = Path(\"embeddings\")\n",
    "\n",
    "K = 10\n",
    "SNIPPET_CHARS = 1000\n",
    "\n",
    "\n",
    "QUERY_SPECS = [\n",
    "    \"курс рубля к доллару\",\n",
    "    \"укрепление рубля причины\",\n",
    "    \"ослабление рубля после решений ФРС\",\n",
    "    \"курс евро к рублю прогноз\",\n",
    "    \"валютный рынок интервенции\",\n",
    "    \"ключевая ставка ЦБ решение\",\n",
    "    \"повышение ключевой ставки последствия\",\n",
    "    \"снижение ключевой ставки эффект на кредиты\",\n",
    "    \"инфляция в России ускорилась\",\n",
    "    \"инфляция замедлилась причины\",\n",
    "    \"индекс потребительских цен ИПЦ\",\n",
    "    \"нефть Brent цена рост\",\n",
    "    \"нефть Brent падение причины\",\n",
    "    \"ОПЕК решение по добыче\",\n",
    "    \"газ цены в Европе\",\n",
    "    \"фондовый рынок России падение\",\n",
    "    \"Мосбиржа индекс IMOEX рост\",\n",
    "    \"акции банков динамика\",\n",
    "    \"санкции влияние на экономику\",\n",
    "    \"бюджет дефицит доходы расходы\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, usecols=[\"message_id\", \"message\"])\n",
    "df[\"message\"] = df[\"message\"].fillna(\"\").astype(str)\n",
    "\n",
    "rowmap = pd.read_csv(ROWMAP_PATH, usecols=[\"row_id\", \"message_id\", \"date\"])\n",
    "rowmap[\"date\"] = pd.to_datetime(rowmap[\"date\"], errors=\"coerce\")\n",
    "\n",
    "m = rowmap.merge(df, on=\"message_id\", how=\"left\")\n",
    "assert m[\"message\"].notna().all(), \"Some messages missing after merge\"\n",
    "texts = m[\"message\"].tolist()\n",
    "\n",
    "emb_files = sorted(EMB_DIR.glob(\"emb_*.npy\"))\n",
    "print(\"Found embeddings:\", [p.name for p in emb_files])\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "MODEL_REGISTRY = {\n",
    "    \"emb_e5_small_fp16.npy\": (\"st\",  \"intfloat/multilingual-e5-small\", \"query: \"),\n",
    "    \"emb_e5_base_fp16.npy\":  (\"st\",  \"intfloat/multilingual-e5-base\",  \"query: \"),\n",
    "    \"emb_e5_large_fp16.npy\": (\"st\",  \"intfloat/multilingual-e5-large\", \"query: \"),\n",
    "    \"emb_minilm_fp16.npy\":   (\"st\",  \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", \"\"),\n",
    "    \"emb_gte_fp16.npy\":      (\"gte\", \"Alibaba-NLP/gte-multilingual-base\", \"\"),\n",
    "}\n",
    "\n",
    "_st_cache = {}\n",
    "_gte_cache = None\n",
    "\n",
    "def encode_query_st(model_name, prefix, query_text):\n",
    "    if model_name not in _st_cache:\n",
    "        mod = SentenceTransformer(model_name)\n",
    "        _st_cache[model_name] = mod\n",
    "    mod = _st_cache[model_name]\n",
    "    q = (prefix + query_text) if prefix else query_text\n",
    "    v = mod.encode([q], normalize_embeddings=True, show_progress_bar=False)\n",
    "    return v.astype(np.float32)[0]\n",
    "\n",
    "def mean_pool(last_hidden, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).to(last_hidden.dtype)\n",
    "    summed = (last_hidden * mask).sum(dim=1)\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-6)\n",
    "    return summed / counts\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode_query_gte(model_name, query_text, max_len=256):\n",
    "    global _gte_cache\n",
    "    if _gte_cache is None:\n",
    "        tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        mdl = AutoModel.from_pretrained(\n",
    "            model_name, trust_remote_code=True, dtype=torch.float16, low_cpu_mem_usage=True\n",
    "        )\n",
    "        mdl.eval()\n",
    "        _gte_cache = (tok, mdl)\n",
    "\n",
    "    tok, mdl = _gte_cache\n",
    "    inputs = tok([query_text], padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    out = mdl(**inputs)\n",
    "    emb = mean_pool(out.last_hidden_state, inputs[\"attention_mask\"])\n",
    "    emb = torch.nn.functional.normalize(emb, p=2, dim=1)\n",
    "    return emb.cpu().numpy().astype(np.float32)[0]\n",
    "\n",
    "def encode_query_for_embfile(embfile_name, query_text):\n",
    "    typ, model_name, prefix = MODEL_REGISTRY[embfile_name]\n",
    "    if typ == \"st\":\n",
    "        return encode_query_st(model_name, prefix, query_text)\n",
    "    elif typ == \"gte\":\n",
    "        return encode_query_gte(model_name, query_text)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown type\")\n",
    "\n",
    "\n",
    "def load_and_normalize_emb(path: Path):\n",
    "    E = np.load(path, mmap_mode=\"r\")\n",
    "    X = E.astype(np.float32)\n",
    "    X /= (np.linalg.norm(X, axis=1, keepdims=True) + 1e-12)\n",
    "    return X\n",
    "\n",
    "def topk_cosine(qvec, X, k=10):\n",
    "    sims = X @ qvec\n",
    "    idx = np.argpartition(-sims, kth=np.arange(k))[:k]\n",
    "    idx = idx[np.argsort(-sims[idx])]\n",
    "    return idx, sims[idx]\n",
    "\n",
    "def snippet(t, n=SNIPPET_CHARS):\n",
    "    t = (t or \"\").strip()\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return t[:n]\n",
    "\n",
    "\n",
    "\n",
    "def dcg(rels):\n",
    "    rels = np.array(rels, dtype=float)\n",
    "    denom = np.log2(np.arange(2, len(rels) + 2))\n",
    "    return float(np.sum((2**rels - 1) / denom))\n",
    "\n",
    "def ndcg_at_k(rels, k=10):\n",
    "    rels = rels[:k]\n",
    "    ideal = sorted(rels, reverse=True)\n",
    "    denom = dcg(ideal)\n",
    "    return 0.0 if denom == 0 else dcg(rels) / denom\n",
    "\n",
    "def precision_at_k(rels, k=10, thr=1):\n",
    "    rels = np.array(rels[:k])\n",
    "    return float(np.mean(rels >= thr))\n",
    "\n",
    "def mrr_at_k(rels, k=10, thr=2):\n",
    "    rels = rels[:k]\n",
    "    for i, r in enumerate(rels, start=1):\n",
    "        if r >= thr:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for emb_path in tqdm(emb_files, desc=\"Embedders\"):\n",
    "    emb_name = emb_path.name\n",
    "    if emb_name not in MODEL_REGISTRY:\n",
    "        print(\"Skip (no registry entry):\", emb_name)\n",
    "        continue\n",
    "\n",
    "    X = load_and_normalize_emb(emb_path)\n",
    "    assert X.shape[0] == len(texts), f\"N mismatch: {emb_name} {X.shape[0]} vs {len(texts)}\"\n",
    "\n",
    "    for q in tqdm(QUERY_SPECS, desc=f\"Queries for {emb_name}\", leave=False):\n",
    "        qv = encode_query_for_embfile(emb_name, q)\n",
    "\n",
    "        idx, sims = topk_cosine(qv, X, k=K)\n",
    "        docs = [snippet(texts[i]) for i in idx]\n",
    "\n",
    "        #LLM judge\n",
    "        scores = judge_with_llm(q, docs) \n",
    "        assert isinstance(scores, list) and len(scores) == K\n",
    "        assert all(s in (0,1,2) for s in scores)\n",
    "\n",
    "        results.append({\n",
    "            \"emb\": emb_name,\n",
    "            \"query\": q,\n",
    "            \"P@10(rel>=1)\": precision_at_k(scores, k=K, thr=1),\n",
    "            \"P@10(rel=2)\": precision_at_k(scores, k=K, thr=2),\n",
    "            \"nDCG@10\": ndcg_at_k(scores, k=K),\n",
    "            \"MRR@10(rel=2)\": mrr_at_k(scores, k=K, thr=2),\n",
    "        })\n",
    "\n",
    "res = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b973c6ae-8e13-4d67-a2c2-2a9bfd652b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@10(rel&gt;=1)</th>\n",
       "      <th>P@10(rel=2)</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>MRR@10(rel=2)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emb_e5_small_fp16.npy</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.954822</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_e5_large_fp16.npy</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_e5_base_fp16.npy</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_gte_fp16.npy</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.882691</td>\n",
       "      <td>0.622917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_minilm_fp16.npy</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.863247</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       P@10(rel>=1)  P@10(rel=2)   nDCG@10  MRR@10(rel=2)\n",
       "emb                                                                      \n",
       "emb_e5_small_fp16.npy         0.920        0.595  0.954822       0.866667\n",
       "emb_e5_large_fp16.npy         0.955        0.665  0.930934       0.872500\n",
       "emb_e5_base_fp16.npy          0.920        0.685  0.927700       0.854167\n",
       "emb_gte_fp16.npy              0.840        0.425  0.882691       0.622917\n",
       "emb_minilm_fp16.npy           0.820        0.440  0.863247       0.708333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = (res.groupby(\"emb\")[[\"P@10(rel>=1)\", \"P@10(rel=2)\", \"nDCG@10\", \"MRR@10(rel=2)\"]]\n",
    "             .mean()\n",
    "             .sort_values(\"nDCG@10\", ascending=False))\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4fec3-505e-4473-b175-9cad0c6d2a37",
   "metadata": {},
   "source": [
    "### Протестим на топ-50 две топовых модели еще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5507fa1-4a64-4847-ba12-236f145d3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Queries: 100%|██████████| 50/50 [07:35<00:00,  9.11s/it]\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def judge_pairs_batched(pairs, batch_size=32, max_new_tokens=40):\n",
    "    out_scores = []\n",
    "    for i in range(0, len(pairs), batch_size):\n",
    "        chunk = pairs[i:i+batch_size]\n",
    "\n",
    "        prompts = []\n",
    "        for q, sn in chunk:\n",
    "            user = f\"Запрос:\\n{q}\\n\\nДокумент:\\n{sn}\\n\"\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": JUDGE_SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ]\n",
    "            prompts.append(\n",
    "                judge_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            )\n",
    "\n",
    "        enc = judge_tokenizer(\n",
    "            prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).to(judge_model.device)\n",
    "\n",
    "        gen_ids = judge_model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            eos_token_id=judge_tokenizer.eos_token_id,\n",
    "            pad_token_id=judge_tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        for b in range(len(chunk)):\n",
    "            prompt_len = int(enc[\"attention_mask\"][b].sum().item())\n",
    "            gen_txt = judge_tokenizer.decode(gen_ids[b][prompt_len:], skip_special_tokens=True)\n",
    "            data = _extract_first_json_obj(gen_txt)\n",
    "            rel = int(data[\"relevance\"]) if isinstance(data, dict) and data.get(\"relevance\") in (0,1,2) else 0\n",
    "            out_scores.append(rel)\n",
    "\n",
    "    return out_scores\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "N_QUERIES_TOTAL = 50\n",
    "N_MANUAL = 20\n",
    "N_AUTO = N_QUERIES_TOTAL - N_MANUAL\n",
    "\n",
    "def first_sentence(text: str) -> str:\n",
    "    t = re.sub(r\"\\s+\", \" \", (text or \"\").strip())\n",
    "    parts = re.split(r\"[.!?]\", t, maxsplit=1)\n",
    "    s = (parts[0] if parts else t).strip()\n",
    "    return (s if s else t)[:140]\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "auto_idx = rng.choice(np.arange(len(texts)), size=N_AUTO, replace=False)\n",
    "auto_queries = [first_sentence(texts[i]) for i in auto_idx]\n",
    "\n",
    "queries = QUERY_SPECS[:N_MANUAL] + auto_queries\n",
    "assert len(queries) == N_QUERIES_TOTAL\n",
    "\n",
    "\n",
    "K = 50\n",
    "\n",
    "def topk_cosine(qvec, X, k=50):\n",
    "    sims = X @ qvec\n",
    "    idx = np.argpartition(-sims, kth=k-1)[:k]\n",
    "    idx = idx[np.argsort(-sims[idx])]\n",
    "    return idx\n",
    "\n",
    "X_base  = load_and_normalize_emb(EMB_DIR / \"emb_e5_base_fp16.npy\")\n",
    "X_large = load_and_normalize_emb(EMB_DIR / \"emb_e5_large_fp16.npy\")\n",
    "\n",
    "assert X_base.shape[0] == len(texts),  f\"X_base rows != texts: {X_base.shape[0]} vs {len(texts)}\"\n",
    "assert X_large.shape[0] == len(texts), f\"X_large rows != texts: {X_large.shape[0]} vs {len(texts)}\"\n",
    "\n",
    "\n",
    "enc_base = SentenceTransformer(\"intfloat/multilingual-e5-base\")\n",
    "enc_large = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "def encode_e5_query(encoder, q: str) -> np.ndarray:\n",
    "    v = encoder.encode([\"query: \" + q], normalize_embeddings=True, show_progress_bar=False)\n",
    "    return v.astype(np.float32)[0]\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for q in tqdm(queries, desc=\"Queries\"):\n",
    "    qv_b = encode_e5_query(enc_base, q)\n",
    "    qv_l = encode_e5_query(enc_large, q)\n",
    "\n",
    "    idx_b = topk_cosine(qv_b, X_base,  k=K)\n",
    "    idx_l = topk_cosine(qv_l, X_large, k=K)\n",
    "\n",
    "    docs_b = [snippet(texts[i]) for i in idx_b]\n",
    "    docs_l = [snippet(texts[i]) for i in idx_l]\n",
    "\n",
    "    # pairwise judge (батчами) — используем твою judge_pairs_batched\n",
    "    scores_b = judge_pairs_batched([(q, d) for d in docs_b], batch_size=32)\n",
    "    scores_l = judge_pairs_batched([(q, d) for d in docs_l], batch_size=32)\n",
    "\n",
    "    rows.append({\n",
    "        \"query\": q,\n",
    "        \"ndcg_base\": ndcg_at_k(scores_b, K),\n",
    "        \"ndcg_large\": ndcg_at_k(scores_l, K),\n",
    "        \"mrr_base\": mrr_at_k(scores_b, K, thr=2),\n",
    "        \"mrr_large\": mrr_at_k(scores_l, K, thr=2),\n",
    "        \"p_base_2\": precision_at_k(scores_b, K, thr=2),\n",
    "        \"p_large_2\": precision_at_k(scores_l, K, thr=2),\n",
    "        \"p_base_1\": precision_at_k(scores_b, K, thr=1),\n",
    "        \"p_large_1\": precision_at_k(scores_l, K, thr=1),\n",
    "    })\n",
    "\n",
    "res = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b8bc2d7-b9bd-4f25-8fa9-78ba35f98f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>e5_base</th>\n",
       "      <th>e5_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDCG@50</td>\n",
       "      <td>0.870425</td>\n",
       "      <td>0.890240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MRR@50(rel=2)</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.927222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P@50(rel=2)</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P@50(rel&gt;=1)</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.426000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          metric   e5_base  e5_large\n",
       "0        nDCG@50  0.870425  0.890240\n",
       "1  MRR@50(rel=2)  0.891667  0.927222\n",
       "2    P@50(rel=2)  0.234000  0.230000\n",
       "3   P@50(rel>=1)  0.413600  0.426000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win-rate base > large | nDCG: 0.36\n",
      "Win-rate base > large | MRR : 0.06\n",
      "Win-rate base > large | P@50(2): 0.3\n"
     ]
    }
   ],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"nDCG@50\", \"MRR@50(rel=2)\", \"P@50(rel=2)\", \"P@50(rel>=1)\"],\n",
    "    \"e5_base\": [\n",
    "        res[\"ndcg_base\"].mean(),\n",
    "        res[\"mrr_base\"].mean(),\n",
    "        res[\"p_base_2\"].mean(),\n",
    "        res[\"p_base_1\"].mean(),\n",
    "    ],\n",
    "    \"e5_large\": [\n",
    "        res[\"ndcg_large\"].mean(),\n",
    "        res[\"mrr_large\"].mean(),\n",
    "        res[\"p_large_2\"].mean(),\n",
    "        res[\"p_large_1\"].mean(),\n",
    "    ],\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "print(\"Win-rate base > large | nDCG:\", float((res[\"ndcg_base\"] > res[\"ndcg_large\"]).mean()))\n",
    "print(\"Win-rate base > large | MRR :\", float((res[\"mrr_base\"]  > res[\"mrr_large\"]).mean()))\n",
    "print(\"Win-rate base > large | P@50(2):\", float((res[\"p_base_2\"] > res[\"p_large_2\"]).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1810a22-edef-4b85-9586-a0ef15230e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1280fc9-bc4f-4e22-beb0-e25603501b6d",
   "metadata": {},
   "source": [
    "## Выбираем e5_large как эмбеддер для TemporalRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5df71d-885e-49c1-998e-a04233f4ad69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "local/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
